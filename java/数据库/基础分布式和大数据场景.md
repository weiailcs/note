### 分布式锁
答：跨JVM的互斥机制来控制资源共享问题

### 分布式事务
答：分布式事务就是指事务的资源分别位于不同的分布式系统的不同节点之上的事务；

### CAP、BASE
答：CAP：指的是在一个分布式系统中，一致性（Consistency）、可用性（Availability）、分区容错性（Partition tolerance），分布式系统在设计时只能在一致性(Consistency)、可用性(Availability)、分区容忍性(Partition Tolerance)中满足两种，无法兼顾三种。

base思想：系统可能处于不一致的状态，但最终会变得一致

ba:Basically Available，基本可用,(系统出现了不可预知的故障，但还是能用，相比较正常的系统而言会有响应时间上的损失和功能上的损失。)

s:Soft State，软状态，状态可以有一段时间不同步,(软状态指的是：允许系统中的数据存在中间状态，并认为该状态不影响系统的整体可用性，即允许系统在多个不同节点的数据副本存在数据延时。)

e:Eventually Consistent，最终一致，最终数据是一致的就可以了，而不是时时保持强一致。(上面说软状态，然后不可能一直是软状态，必须有个时间期限。在期限过后，应当保证所有副本保持数据一致性，从而达到数据的最终一致性。这个时间期限取决于网络延时、系统负载、数据复制方案设计等等因素。)

- 一致性：比如说有三个服务器A、B、C，三个结点都存储了用户数据，三个结点的数据需要保持同一时刻数据一致性
- 可用性：服务A、B、C三个结点，其中一个结点宕机不影响整个集群对外提供服务，如果只有服务A结 点，当服务A宕机整个系统将无法提供服务，增加服务B、C是为了保证系统的可用性。
- 分区容忍性：分区容忍性就是允许系统通过网络协同工作，分区容忍性要解决由于网络分区 导致数据的不完整及无法访问等问题。

### 分布式ID
答：数据库的ID字段在单体的情况下可以使用自增来作为ID，但是对数据分库分表后一定需要一个唯一的ID来标识一条数据，这个ID就是分布式ID。（对于分布式ID而言，也需要具备分布式系统的特点：高并发，高可用，高性能等特点。）

### 分布式协议
答：

### 布隆过滤器
答：布隆过滤器（由布隆于1970年提出），它实际上是由一段很长的二进制向量和一系列随机映射函数组成。布隆过滤器可以用于检索一个元素是否在一个集合中。它的优点是空间效率和查询时间都比一般的算法要好的多，缺点是有一定的误识别率和删除困难。

是不是描述的比较抽象？那就直接了解其原理吧！

还是以上面的例子为例：

哈希算法得出的Integer的哈希值最大为：

Integer.MAX_VALUE=2147483647

意思就是任何一个URL的哈希都会在0~2147483647之间。

那么可以定义一个 2147483647 长度的byte数组，用来存储集合所有可能的值。为了存储这个byte数组，系统只需要：

2147483647/8/1024/1024=256M

比如：某个URL（X）的哈希是2，那么落到这个byte数组在第二位上就是1，这个byte数组将是：000….00000010.

下面,我们将这20亿个数全部哈希并落到byte数组中:

如果byte数组上的第二位是1，那么这个URL（X）可能存在。为什么是可能？因为有可能其它URL因哈希碰撞哈希出来的也是2，这就是误判。

但是如果这个byte数组上的第二位是0，那么这个URL（X）就一定不存在集合中。

**多次哈希**
![image](https://pic3.zhimg.com/80/v2-e5150e9c3c4da8c4386c955c9fda0c2e_720w.jpg)
为了减少因哈希碰撞导致的误判概率，可以对这个URL（X）用不同的哈希算法进行N次哈希，得出N个哈希值，落到这个byte数组上，如果这N个位置没有都为1，那么这个URL（X）就一定不存在集合中。

**使用场景：**

布隆过滤器的巨大用处就是，能够迅速判断一个元素是否在一个集合中。它的常用使用场景如下:

1、黑名单 : 反垃圾邮件，从数十亿个垃圾邮件列表中判断某邮箱是否垃圾邮箱（同理，垃圾短信）
2、URL去重 : 网页爬虫对URL的去重，避免爬取相同的URL地址
3、单词拼写检查
4、Key-Value缓存系统的Key校验 (缓存穿透) : 缓存穿透，将所有可能存在的数据缓存放到布隆过滤器中，当黑客访问不存在的缓存时迅速返回避免缓存及DB挂掉。
5、ID校验，比如订单系统查询某个订单ID是否存在，如果不存在就直接返回。

### URL黑名单问题：判断值是否已经存在于集合中
答：用布隆过滤器

### 20亿个32位整数中出现次数最多的数（内存要求限制2GB）
答：想要在很多整数中找到出现次数最多的数，通常的做法是使用哈希表对出现的每一个数做词频统计，哈希表的key是某一个整数，value是这个数出现的次数。就本题来说，一共有20亿个数，哪怕只是一个数出现了20亿次，用32位的整数也可以表示其出现的次数而不会产生溢出，所以哈希表的key需要占用4B，value也是4B。那么哈希表的一条记录(key，value)需要占用8B。最极端的情况是20亿个数都不同，那么在哈希表中可能需要产生20亿条记录，需要15g内存，这样内存会不够用，所以一次性用哈希表统计20亿个数的办法是有很大风险的。

解决办法是把包含20亿个数的大文件用哈希函数分成16个小文件，根据哈希函数的性质，同一种数不可能被哈希到不同的小文件上，同时每个小文件中不同的数一定不会大于2亿种，假设哈希函数足够好。然后对每一个小文件用哈希表来统计其中每种数出现的次数，这样我们就得到了16个小文件中各自出现次数最多的数，还有各自的次数统计。接下来只要选出这16个小文件各自的第一名中谁出现的次数最多即可。

### 40亿个非负整数没出现的数：
答：

### 找到100亿个URL重复的URL
答：

### 40亿非负整数出现两次的数：
答：

### 大数据的中位数，桶排序：
答：