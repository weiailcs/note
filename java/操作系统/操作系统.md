### java内存区域
![image](https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-11/ff96fed0e2a354bb16bbc84dcedf503a.png)

没有操作系统并不是所有软件不能运行，eg：基于底层硬件操作的应用软件

### 操作系统
答：
1. 操作系统（Operating System，简称 OS）是管理计算机硬件与软件资源的程序，是计算机的基石。
2. 操作系统本质上是一个运行在计算机上的软件程序 ，用于管理计算机硬件和软件资源。 举例：运行在你电脑上的所有应用程序都通过操作系统来调用系统内存以及磁盘等等硬件。
3. 操作系统存在屏蔽了硬件层的复杂性。 操作系统就像是硬件使用的负责人，统筹着各种相关事项。
4. 操作系统的内核（Kernel）是操作系统的核心部分，它负责系统的内存管理，硬件设备的管理，文件系统的管理以及应用程序的管理。

### 并行和并发有什么区别？
答：并行是指两个或多个事件在同一时刻发生；并发是指两个或多个事件在同一时间间隔发生。

### 进程和线程的区别
答：一个程序至少有一个进程，一个进程至少有一个线程。进程是程序运行和资源分配的基本单位。进程拥有独立的内存单元，多个线程共享内存单元。线程是进程的一个实体，是CPU调度和分配的基本单位。同一个进程的多个线程可以并发执行。

### 协程
答：是一种比线程更加轻量级的存在，一个线程中可以有多个协程。协程之间与线程一样是互不干扰的，独立的。协程的切换是由程序自己控制，而线程的切换是由系统控制。

### 进程间的通信方式
答：
- 管道：具有亲缘关系（父子和兄弟）的两个进程之间的通信。
- 命名管道：任意两个进程之间的通信。
- 信号：信号是一种比较复杂的通信方式，用于通知接收线程某个事件已经发生
- 消息队列:是由消息的列表存放在内存中，并由消息队列标识符统一标识。
- 信号量：是一个计数器，可以用来控制多线程对共享资源的访问（作为一种锁机制，防止某进程访问共享资源时，其他进程也访问该资源）。
- 共享内存：共享内存就是映射一段能被其他进程访问的内存，这段内存由一个进程创建，但多个进程可以访问。
- 套接字：此方法主要用于在客户端和服务器之间通过网络进行通信。套接字是支持 TCP/IP 的网络通信的基本操作单元，可以看做是不同主机之间的进程进行双向通信的端点，简单的说就是通信的两方的一种约定，用套接字中的相关函数来完成通信过程。


### 线程间的同步方式
答：
1. 互斥量：采用互斥对象机制，只有拥有互斥对象的线程才有访问资源的权限
2. 信号量：允许同一时刻多个线程访问同一资源，但是线程数有限制
3. 事件：通过通知操作保持多线程同步

### 线程有哪些状态？
答：
- 创建：创建了线程对象，但是没有调用start方法
- 就绪：调用了start方法，但是线程调度程序没有将该线程设置为当前线程
- 运行：线程调度程序将就绪状态的线程设置为当前线程
- 阻塞：正在运行的线程被暂停，等待某个事件发生后继续运行
- 死亡：线程的run方法执行结束或调用了stop方法

### 创建线程的几种方式
答：
1. 继承Thread类创建线程：创建Thread类的子类，实现run方法，创建子类实例，调用start方法启动线程。
2. 实现Runnable接口创建线程：创建Runnable接口的实现类，重写run方法，创建实现类实例，并以此来创建线程对象，调用start方法启动线程。
3. 实现Callable接口创建线程：创建Callable接口的实现类，实现call方法，创建实现类的实例，并以此来创建线程对象，调用start方法启动线程。

### Runnable和Callable的区别
答：Runnable接口中的run方法没有返回值，只是单纯的执行run中的代码；Callable接口中的call方法是有返回值的，和Future、FutureTask配合来获取异步执行的结果。

### sleep()和wait()的区别
答：
- 相同：sleep和wait都能够使线程暂停
- 不同：sleep方法不会释放锁，其它线程无法访问这个对象，方法执行结束会自动唤醒；wait方法会释放锁，方法执行结束不会自动唤醒，通过notify、notifyall唤醒。

### notify和notifyall的区别
答：notify()是唤醒一个wait线程，后者是唤醒所有wait线程

### 进程的调度算法
答：
- 先到先服务(FCFS)调度算法 : 从就绪队列中选择一个最先进入该队列的进程为之分配资源，使它立即执行并一直执行到完成或发生某事件而被阻塞放弃占用 CPU 时再重新调度。
- 短作业优先(SJF)的调度算法 : 从就绪队列中选出一个估计运行时间最短的进程为之分配资源，使它立即执行并一直执行到完成或发生某事件而被阻塞放弃占用 CPU 时再重新调度。
- 时间片轮转调度算法 : （时间片轮转调度是一种最古老，最简单，最公平且使用最广的算法，又称 RR(Round robin)调度。）每个进程被分配一个时间段，称作它的时间片，即该进程允许运行的时间。
- 多级反馈队列调度算法：（前面介绍的几种进程调度的算法都有一定的局限性。如短进程优先的调度算法，仅照顾了短进程而忽略了长进程 。)多级反馈队列调度算法既能使高优先级的作业得到响应又能使短作业（进程）迅速完成。，因而它是目前被公认的一种较好的进程调度算法，UNIX 操作系统采取的便是这种调度算法。
- 优先级调度 ： 为每个流程分配优先级，首先执行具有最高优先级的进程，依此类推。具有相同优先级的进程以 FCFS 方式执行。可以根据内存要求，时间要求或任何其他资源要求来确定优先级。

### 死锁的必要条件
答：
- 死锁的必要条件：
1. 互斥：一个资源每次只能被一个进程使用。
2. 请求和保持：一个进程因请求资源而阻塞时，对已获得的资源保持不放。
3. 不可剥夺：进程已获得的资源，在未使用完之前，不能强行剥夺。
4. 环路等待：:若干进程之间形成一种头尾相接的循环等待资源关系。
### 处理死锁的基本方法
1. 死锁预防：破坏死锁的四个条件中的一个或几个条件（限制条件往往太严格，因而导致系统资源利用率和系统吞吐量降低）
2. 死锁避免：允许前三个必要条件，但通过明智的选择，确保永远不会到达死锁点
3. 死锁检测：不须实现采取任何限制性措施，而是允许系统在运行过程发生死锁，但可通过系统设置的检测机构及时检测出死锁的发生，并精确地确定于死锁相关的进程和资源，然后采取适当的措施，从系统中将已发生的死锁清除掉。
4. 死锁解除：与死锁检测相配套的一种措施。当检测到系统中已发生死锁，需将进程从死锁状态中解脱出来。**常用方法：撤销或挂起一些进程，以便回收一些资源，再将这些资源分配给已处于阻塞状态的进程**。

- 死锁预防
1. 破坏互斥：将临界资源改为共享资源（eg:SPOOLing技术）。缺点：可行性不高，很多时候无法破坏互斥条件。
2. 破坏请求和保持：运行前，一次性分配好所有资源。 缺点：资源利用率低；可能导致饥饿
3. 破坏不可剥夺：1）申请资源得不到满足时释放已拥有所有资源 2）申请的资源被其它进程占用时，由操作系统协助剥夺（考虑优先级） 缺点：实现复杂；剥夺资源可能导致部分工作失效；反复申请和释放可能导致系统开销大；可能导致饥饿
4. 破坏环路等待：按序申请资源 缺点：不方便增加新设备；会导致资源浪费；用户编程麻烦

- 死锁避免
1. 进程启动拒绝：如果一个进程的请求会导致死锁，则不启动该进程。
2. 资源分配拒绝：如果一个进程增加的资源请求会导致死锁，则不允许此分配(银行家算法)

- 银行家算法
1. 如果request<=need，转向步骤2；否则认为出错，因为请求资源大于需要资源；
2. 如果request<=available，转向步骤3,；否则尚无足够资源，进程p阻塞；
3. 系统尝试为把资源分配给进程P，并修改available、allocation和need的数值；
4. 系统执行安全性算法，检查此次分配后系统是否处于安全状态，若安全，才正式将资源分配给进程P，否则将本次试探性分配作废，让进程P等待。

### 什么是虚拟内存(Virtual Memory)?
答：虚拟内存 使得应用程序认为它拥有连续的可用的内存（一个连续完整的地址空间），而实际上，它通常是被分隔成多个物理内存碎片，还有部分暂时存储在外部磁盘存储器上，在需要时进行数据交换。与没有使用虚拟内存技术的系统相比，使用这种技术的系统使得大型程序的编写变得更容易，对真正的物理内存（例如 RAM）的使用也更有效率。目前，大多数操作系统都使用了虚拟内存，如 Windows 家族的“虚拟内存”；Linux 的“交换空间”等。

### 操作系统的内存管理主要是做什么？
答：主要负责内存的分配与回收，另外地址转换也就是将逻辑地址转换成相应的物理地址等功能也是操作系统内存管理做的事情。

### 操作系统内存管理机制
答：分为连续分配管理方式和非连续分配管理方式。连续分配管理方式指的是给一个应用程序分配一段连续的内存空间；非连续分配管理方式指给一个应用程序分配离散的内存空间。
- 块式管理：古老的内存管理方式，将内存分为固定大小的块，每个块只包含一个进程，如果程序运行需要内存，操作系统会给它一个块。
- 分页管理：把主存分为大小相等且固定队一页一页的形式。（页较小，无实际意义）。
- 分段管理：把主存分为一段段的（，每一段空间比一页的空间小很多，段有实际意义）。
- 段页式管理：结合了段式管理和页式管理的优点。简单来说段页式管理机制就是把主存先分成若干段，每个段又分成若干页，也就是说 段页式管理机制 中段与段之间以及段的内部的都是离散的。

### 快表和多级页表
答：
**快表**：为了解决虚拟地址到物理地址的转换速度，操作系统在 页表方案 基础之上引入了 快表 来加速虚拟地址到物理地址的转换。我们可以把快表理解为一种特殊的高速缓冲存储器（Cache），其中的内容是页表的一部分或者全部内容。作为页表的 Cache，它的作用与页表相似，但是提高了访问速率。由于采用页表做地址转换，读写内存数据时 CPU 要访问两次主存。有了快表，有时只要访问一次高速缓冲存储器，一次主存，这样可加速查找并提高指令执行速度。

使用快表之后的地址转换流程是这样的：
- 根据虚拟地址中的页号查快表；
- 如果该页在快表中，直接从快表中读取相应的物理地址；
- 如果该页不在快表中，就访问内存中的页表，再从页表中得到物理地址，同时将页表中的该映射表项添加到快表中；
- 当快表填满后，又要登记新页时，就按照一定的淘汰策略淘汰掉快表中的一个页。

看完了之后你会发现快表和我们平时经常在我们开发的系统使用的缓存（比如 Redis）很像，的确是这样的，操作系统中的很多思想、很多经典的算法，你都可以在我们日常开发使用的各种工具或者框架中找到它们的影子。

**多级页表**：引入多级页表的主要目的是为了避免把全部页表一直放在内存中占用过多空间，特别是那些根本就不需要的页表就不需要保留在内存中。多级页表属于时间换空间的典型场景，具体可以查看下面这篇文章

**总结**：为了提高内存的空间性能，提出了多级页表的概念；但是提到空间性能是以浪费时间性能为基础的，因此为了补充损失的时间性能，提出了快表（即 TLB）的概念。 不论是快表还是多级页表实际上都利用到了程序的局部性原理

### 缺页中断
答：就是要访问的页不在主存，需要操作系统将其调入主存后再进行访问。

### 页面置换算法的作用?常见的页面置换算法有哪些?
答：作用：当发生缺页中断时，如果当前内存中并没有空闲的页面，操作系统就必须在内存选择一个页面将其移出内存，以便为即将调入的页面让出空间。用来选择淘汰哪一页的规则叫做页面置换算法，我们可以把页面置换算法看成是淘汰页面的规则。
- OPT 页面置换算法（最佳页面置换算法） ：最佳(Optimal, OPT)置换算法所选择的被淘汰页面将是以后永不使用的，或者是在最长时间内不再被访问的页面,这样可以保证获得最低的缺页率。但由于人们目前无法预知进程在内存下的若千页面中哪个是未来最长时间内不再被访问的，因而该算法无法实现。一般作为衡量其他置换算法的方法。
- FIFO（First In First Out） 页面置换算法（先进先出页面置换算法） : 总是淘汰最先进入内存的页面，即选择在内存中驻留时间最久的页面进行淘汰。
- LRU （Least Currently Used）页面置换算法（最近最久未使用页面置换算法） ：LRU算法赋予每个页面一个访问字段，用来记录一个页面自上次被访问以来所经历的时间 T，当须淘汰一个页面时，选择现有页面中其 T 值最大的，即最近最久未使用的页面予以淘汰。
- LFU （Least Frequently Used）页面置换算法（最少使用页面置换算法） : 该置换算法选择在之前时期使用最少的页面作为淘汰页。

### 磁盘调度算法
答：
1. 先来先服务算法（FCFS）：根据进程请求访问磁盘的先后顺序进行调度。
2. 最短寻道时间优先算法（SSTF）：优先处理的磁道是与当前磁头最近的磁道。贪心算法的思想，可以保证每次寻道时间最短，但是不能保证总的寻道时间最短。缺点：会导致饥饿
3. 扫描算法（SCAN）：磁头只有移动到请求最外侧磁道或最内侧磁道才可以反向移动，如果在磁头移动的方向上已经没有请求，就可以立即改变磁头移动，不必移动到最内/外侧的磁道。也叫电梯算法。缺点：对各个位置的响应频率不平均。
4. 循环扫描算法（C-SCAN）：只有磁头朝某个方向上移动时才响应请求，改变方向时不响应请求，直接移动到最边缘需要响应的磁道。

### 阻塞式io和非阻塞式io的区别
答：（JDK1.4引入的类库）在阻塞模式下，若从网络流中读取不到指定大小的数据量，阻塞IO就在那里阻塞着。比如，已知后面会有10个字节的数据发过来，但是我现在只收到8个字节，那么当前线程就在那傻傻地等到下一个字节的到来，对，就在那等着，啥事也不做，直到把这10个字节读取完，这才将阻塞放开通行。

在非阻塞模式下，若从网络流中读取不到指定大小的数据量，非阻塞IO就立即通行。比如，已知后面会有10个字节的数据发过来，但是我现在只收到8个字节，那么当前线程就读取这8个字节的数据，读完后就立即返回，等另外两个字节再来的时候再去读取。

### io多路复用，讲一下select、poll、epoll
答：
- select：该函数允许进程指示内核等待多个事件中的任何一个发生，并仅在有一个或多个事件发生或经历一段指定的时间后才唤醒它
- poll:poll的机制与select类似，与select在本质上没有多大差别，(只是描述fd集合的方式不同，poll使用pollfd结构而不是select的fd_set结构，)管理多个描述符也是进行轮询，根据描述符的状态进行处理，但是poll没有最大文件描述符数量的限制。poll和select同样存在一个缺点就是，包含大量文件描述符的数组被整体复制于用户态和内核的地址空间之间，而不论这些文件描述符是否就绪，它的开销随着文件描述符数量的增加而线性增大。
- epoll:相对于select和poll来说，epoll更加灵活，没有描述符限制。epoll使用一个文件描述符管理多个描述符，将用户关系的文件描述符的事件存放到内核的一个事件表中，这样在用户空间和内核空间的copy只需一次。

### NIO、BIO、同步和异步、阻塞和非阻塞的理解
答：
- 同步,指的是用户进程触发IO操作并等待或者轮询的去查看IO操作是否就绪
- 异步,是指用户进程触发IO操作以后便开始做自己的事情，而当IO操作已经完成的时候会得到IO完成的通知（异步的特点就是通知）
- 阻塞和非阻塞，是针对于进程在访问数据的时候，根据IO操作的就绪状态来采取的不同方式，说白了是一种读取或者写入操作函数的实现方式，阻塞方式下读取或者写入函数将一直等待，而非阻塞方式下，读取或者写入函数会立即返回一个状态值。  
- 同步阻塞IO（JAVA BIO）： 
    同步并阻塞，服务器实现模式为一个连接一个线程，即客户端有连接请求时服务器端就需要启动一个线程进行处理，如果这个连接不做任何事情会造成不必要的线程开销，当然可以通过线程池机制改善。 
- 同步非阻塞IO(Java NIO) ： 同步非阻塞，服务器实现模式为一个请求一个线程，即客户端发送的连接请求都会注册到多路复用器上，多路复用器轮询到连接有I/O请求时才启动一个线程进行处理。用户进程也需要时不时的询问IO操作是否就绪，这就要求用户进程不停的去询问。3
- 异步阻塞IO（Java NIO）：  
   此种方式下是指应用发起一个IO操作以后，不等待内核IO操作的完成，等内核完成IO操作以后会通知应用程序，这其实就是同步和异步最关键的区别，同步必须等待或者主动的去询问IO是否完成，那么为什么说是阻塞的呢？因为此时是通过select系统调用来完成的，而select函数本身的实现方式是阻塞的，而采用select函数有个好处就是它可以同时监听多个文件句柄（如果从UNP的角度看，select属于同步操作。因为select之后，进程还需要读写数据），从而提高系统的并发性！  
- （Java AIO(NIO.2)）异步非阻塞IO:  
   在此种模式下，用户进程只需要发起一个IO操作然后立即返回，等IO操作真正的完成以后，应用程序会得到IO操作完成的通知，此时用户进程只需要对数据进行处理就好了，不需要进行实际的IO读写操作，因为真正的IO读取或者写入操作已经由内核完成了。


### 进程在自己虚拟地址空间都是什么
答：

### 孤儿进程、僵尸进程
答： 当一个进程使用了fork函数会创建一个新的子进程，那么就会存在两个问题，一个是子进程没有结束但是父进程结束了，另一个是子进程结束了但是父进程没有回收子进程的资源。这两种情况就产生了孤儿进程和僵尸进程。(首先先来明确一个知识点，在每个进程退出的时候，内核释放该进程所有的资源，包括打开的文件，占用的内存等。但是仍然为其保留一定的信息（包括进程号the process ID，退出状态the termination status of the process，运行时间the amount of CPU time taken by the process等）)

孤儿进程：当子进程还没有结束的时候，父进程先结束了，那么此时的子进程就叫做孤儿进程。

僵尸进程：任何一个子进程在结束后，并不是马上消失掉，而是留下一些资源等待父进程处理，那么僵尸进程就是当子进程比父进程先结束，而父进程又没有释放子进程占用的资源，此时子进程将成为一个僵尸进程。

















### 分页机制和分段机制有哪些共同点和区别呢？
答：
- **共同点** ：1）分页机制和分段机制都是为了提高内存利用率，较少内存碎片。2）页和段都是离散存储的，所以两者都是离散分配内存的方式。但是，每个页和段中的内存是连续的。
- **区别**：1）页的大小是固定的，由操作系统决定；而段的大小不固定，取决于我们当前运行的程序。2）分页仅仅是为了满足操作系统内存管理的需求，而段是逻辑信息的单位，在程序中可以体现为代码段，数据段，能够更好满足用户的需要。

###  逻辑(虚拟)地址和物理地址
答：逻辑地址由操作系统决定。物理地址指的是真实物理内存中地址
，更具体一点来说就是内存地址寄存器中的地址。物理地址是内存单元真正的地址。



### CPU 寻址了解吗?
答：现代处理器使用的是一种称为 **虚拟寻址**(Virtual Addressing) 的寻址方式。**使用虚拟寻址，CPU 需要将虚拟地址翻译成物理地址，这样才能访问到真实的物理内存**。 实际上完成虚拟地址转换为物理地址转换的硬件是 CPU 中含有一个被称为 **内存管理单元**（Memory Management Unit, MMU） 的硬件

### 为什么需要虚拟地址空间?
答：没有虚拟地址空间的时候，**程序都是直接访问和操作的都是物理内存** 。这样会带来许多问题，eg:1)用户程序可以访问任意内存，寻址内存的每个字节，这样就很容易（有意或者无意）破坏操作系统，造成操作系统崩溃。2)想要同时运行多个程序特别困难，比如你想同时运行一个微信和一个 QQ 音乐都不行。为什么呢？举个简单的例子：微信在运行的时候给内存地址 1xxx 赋值后，QQ 音乐也同样给内存地址 1xxx 赋值，那么 QQ 音乐对内存的赋值就会覆盖微信之前所赋的值，这就造成了微信这个程序就会崩溃。

**总结来说：如果直接把物理地址暴露出来的话会带来严重问题，比如可能对操作系统造成伤害以及给同时运行多个程序造成困难**。

通过虚拟地址访问内存有以下优势：
- 程序可以使用一系列相邻的虚拟地址来访问物理内存中不相邻的大内存缓冲区。
- 程序可以使用一系列虚拟地址来访问大于可用物理内存的内存缓冲区。当物理内存的供应量变小时，内存管理器会将物理内存页（通常大小为 4 KB）保存到磁盘文件。数据或代码页会根据需要在物理内存与磁盘之间移动。
- 不同进程使用的虚拟地址彼此隔离。一个进程中的代码无法更改正在由另一进程或操作系统使用的物理内存

### 局部性原理
答：（要想更好地理解虚拟内存技术，必须要知道计算机中著名的**局部性原理**）

局部性原理表现在以下两个方面：
1. 时间局部性 ：如果程序中的某条指令一旦执行，不久以后该指令可能再次执行；如果某数据被访问过，不久以后该数据可能再次被访问。产生时间局部性的典型原因，是由于在程序中存在着大量的循环操作。
2. 空间局部性 ：一旦程序访问了某个存储单元，在不久之后，其附近的存储单元也将被访问，即程序在一段时间内所访问的地址，可能集中在一定的范围之内，这是因为指令通常是顺序存放、顺序执行的，数据也一般是以向量、数组、表等形式簇聚存储的。

时间局部性是通过将近来使用的指令和数据保存到高速缓存存储器中，并使用高速缓存的层次结构实现。空间局部性通常是使用较大的高速缓存，并将预取机制集成到高速缓存控制逻辑中实现。虚拟内存技术实际上就是建立了 “内存一外存”的两级存储器的结构，利用局部性原理实现髙速缓存。

### 虚拟存储器
答：基于局部性原理，在程序装入时，可以将程序的一部分装入内存，而将其他部分留在外存，就可以启动程序执行。由于外存往往比内存大很多，所以我们运行的软件的内存大小实际上是可以比计算机系统实际的内存大小大的。在程序执行过程中，当所访问的信息不在内存时，由操作系统将所需要的部分调入内存，然后继续执行程序。另一方面，操作系统将内存中暂时不使用的内容换到外存上，从而腾出空间存放将要调入内存的信息。这样，计算机好像为用户提供了一个比实际内存大的多的存储器——虚拟存储器。